{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "RegularizedRegresions_noBrands.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nietzscholas9000/UsedCarsProject/blob/master/RegularizedRegresions_noBrands.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGsHZSF_U5FG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Non regularized poynomial regression followed by ridge, lasso, and elasticNet\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "#Loading the dataset\n",
        "dataset = pd.read_csv('processed_without_modelbrand.csv')\n",
        "\n",
        "X = dataset.iloc[:,2:].values \n",
        "y = dataset.iloc[:,1].values\n",
        "\n",
        "#Splitting the data into Training Set and Test Set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YfGuLN8U5FQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2eff222f-af39-49eb-8980-d35ca48cfa68"
      },
      "source": [
        "#Fitting Multiple Linear Regression to Training Set\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# mlrObj = LinearRegression()\n",
        "# mlrObj.fit(X_train,y_train)\n",
        "\n",
        "#Polynomial Regression No Regularization\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "polyFeatureObj = PolynomialFeatures(degree=3)\n",
        "X_poly = polyFeatureObj.fit_transform(X_train)\n",
        "X_poly_test = polyFeatureObj.fit_transform(X_test)  \n",
        "prObj = LinearRegression()\n",
        "prObj.fit(X_poly, y_train)\n",
        "# runs out of memory above 3 degrees on normal colab\n",
        "\n",
        "y_pred = enObj.predict(X_test)\n",
        "print(prObj.score(X_poly_test,y_test))\n",
        "print(y_test)\n",
        "print(y_pred)\n",
        "print(mean_squared_error(10**y_test, 10**y_pred))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8005625104685701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3AqjTXJU5FZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ridge\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "#Loading the dataset\n",
        "dataset = pd.read_csv('processed_without_modelbrand.csv')\n",
        "\n",
        "X = dataset.iloc[:,2:].values \n",
        "y = dataset.iloc[:,1].values\n",
        "\n",
        "#Splitting the data into Training Set and Test Set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
        "\n",
        "\n",
        "\n",
        "#Polynomial Regression with Ridge\n",
        "# runs out of memory above 3 degrees on normal colab\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import Ridge\n",
        "polyFeatureObj = PolynomialFeatures(degree=3)\n",
        "X_poly = polyFeatureObj.fit_transform(X_train)\n",
        "X_poly_test = polyFeatureObj.fit_transform(X_test) \n",
        "ridgeObj = Ridge()\n",
        "ridgeObj.fit(X_poly, y_train)\n",
        "\n",
        "y_pred = ridgeObj.predict(X_test)\n",
        "print(ridgeObj.score(X_poly_test,y_test))\n",
        "print(y_test)\n",
        "print(y_pred)\n",
        "print(mean_squared_error(10**y_test, 10**y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhva7t--U5Ff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "44e3abad-8ca0-4cc1-efc9-0f50aab890c3"
      },
      "source": [
        "# Lasso\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "#Loading the dataset\n",
        "dataset = pd.read_csv('processed_without_modelbrand.csv')\n",
        "\n",
        "X = dataset.iloc[:,2:].values \n",
        "y = dataset.iloc[:,1].values\n",
        "\n",
        "#Splitting the data into Training Set and Test Set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
        "\n",
        "\n",
        "#Polynomial Regression with Lasso\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import Lasso\n",
        "polyFeatureObj = PolynomialFeatures(degree=3)\n",
        "X_poly = polyFeatureObj.fit_transform(X_train)\n",
        "X_poly_test = polyFeatureObj.fit_transform(X_test)  \n",
        "lassoObj = Lasso()\n",
        "lassoObj.fit(X_poly, y_train)\n",
        "\n",
        "\n",
        "y_pred = lassoObj.predict(X_test)\n",
        "print(lassoObj.score(X_poly_test,y_test))\n",
        "print(y_test)\n",
        "print(y_pred)\n",
        "print(mean_squared_error(10**y_test, 10**y_pred))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6393.461759487065, tolerance: 5.617437698763439\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7727468879054702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AsoYTH0U5Fk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "8b21fb72-de93-4c8c-fd17-d2f2a52cd093"
      },
      "source": [
        "# ElasticNet\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "#Loading the dataset\n",
        "dataset = pd.read_csv('processed_without_modelbrand.csv')\n",
        "\n",
        "X = dataset.iloc[:,2:].values \n",
        "y = dataset.iloc[:,1].values\n",
        "\n",
        "#Splitting the data into Training Set and Test Set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
        "\n",
        "\n",
        "#Polynomial Regression with ElasticNet\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import ElasticNet\n",
        "polyFeatureObj = PolynomialFeatures(degree=3)\n",
        "X_poly = polyFeatureObj.fit_transform(X_train)\n",
        "X_poly_test = polyFeatureObj.fit_transform(X_test)  \n",
        "enObj = ElasticNet(l1_ratio=1)\n",
        "enObj.fit(X_poly, y_train)\n",
        "\n",
        "print(enObj.score(X_poly_test,y_test))\n",
        "\n",
        "y_pred = enObj.predict(X_test)\n",
        "\n",
        "print(y_test)\n",
        "print(y_pred)\n",
        "print(mean_squared_error(10**y_test, 10**y_pred))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7727468879054702\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6393.461759487065, tolerance: 5.617437698763439\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2532e96ff0e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_poly_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \"\"\"\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    792\u001b[0m                                    dense_output=True) + self.intercept_\n\u001b[1;32m    793\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m--> 209\u001b[0;31m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
            "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1540 is different from 19)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU6azWNfU5Fv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Predicting on the Test Set\n",
        "print(prObj.score(X_poly_test,y_test))\n",
        "y_pred = prObj.predict(X_poly_test)\n",
        "print(y_pred)\n",
        "print(y_test)\n",
        "\n",
        "\n",
        "# calculating mean squared error from of the models\n",
        "MSE = np.mean((y_test - y_pred)**2)\n",
        "MSE_sig = np.mean((y_test - y_sig_pred)**2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}